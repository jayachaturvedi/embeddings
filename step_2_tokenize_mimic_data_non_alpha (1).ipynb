{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from collections import Counter\n",
    "import spacy\n",
    "import scispacy\n",
    "import re\n",
    "import gzip\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install \"thinc==7.4.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x7f3c28172220>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#spacy.load('en') #not sure how to make this work!\n",
    "spacy.load('en_core_sci_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en import English\n",
    "#nlp = English(parser=False, entity=False)\n",
    "nlp = English()\n",
    "\n",
    "#This isn't working either. They all want this thinc module which just doesn't seem to be working or exist?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en.examples import sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "filecount = 0\n",
    "no_of_text_fields = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./NOTEEVENTS_all_text.csv') #all notes as df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Coronary artery bypass graft (CABG)\\n   Assess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subdural hemorrhage (SDH)\\n   Assessment:\\n   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coronary artery bypass graft (CABG)\\n   Assess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Coronary artery bypass graft (CABG)\\n   Assess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Demographics\\n   Day of intubation:\\n   Day of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Coronary artery bypass graft (CABG)\\n   Assess...\n",
       "1  Subdural hemorrhage (SDH)\\n   Assessment:\\n   ...\n",
       "2  Coronary artery bypass graft (CABG)\\n   Assess...\n",
       "3  Coronary artery bypass graft (CABG)\\n   Assess...\n",
       "4  Demographics\\n   Day of intubation:\\n   Day of..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if spacy not working, try this approach: https://stackoverflow.com/questions/33098040/how-to-use-word-tokenize-in-data-frame\n",
    "Else, skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# skip\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip\n",
    "\n",
    "df['tokenized_sents'] = df.apply(lambda row: nltk.word_tokenize(row['text']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip # For finding the length of each text try to use apply and lambda function again:\n",
    "\n",
    "df['sents_length'] = df.apply(lambda row: len(row['tokenized_sents']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized_sents</th>\n",
       "      <th>sents_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76 y/o M initially admitted to [**Hospital3 33...</td>\n",
       "      <td>[76, y/o, M, initially, admitted, to, [, *, *,...</td>\n",
       "      <td>901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54yr man with hx metastatic renal cell ca, c/o...</td>\n",
       "      <td>[54yr, man, with, hx, metastatic, renal, cell,...</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chief Complaint:\\n   24 Hour Events:\\n   - Per...</td>\n",
       "      <td>[Chief, Complaint, :, 24, Hour, Events, :, -, ...</td>\n",
       "      <td>1135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chief Complaint:  Acute Hepatitis\\n   HPI:\\n  ...</td>\n",
       "      <td>[Chief, Complaint, :, Acute, Hepatitis, HPI, :...</td>\n",
       "      <td>1976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chief Complaint:\\n   HPI:\\n   24 Hour Events:\\...</td>\n",
       "      <td>[Chief, Complaint, :, HPI, :, 24, Hour, Events...</td>\n",
       "      <td>567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  76 y/o M initially admitted to [**Hospital3 33...   \n",
       "1  54yr man with hx metastatic renal cell ca, c/o...   \n",
       "2  Chief Complaint:\\n   24 Hour Events:\\n   - Per...   \n",
       "3  Chief Complaint:  Acute Hepatitis\\n   HPI:\\n  ...   \n",
       "4  Chief Complaint:\\n   HPI:\\n   24 Hour Events:\\...   \n",
       "\n",
       "                                     tokenized_sents  sents_length  \n",
       "0  [76, y/o, M, initially, admitted, to, [, *, *,...           901  \n",
       "1  [54yr, man, with, hx, metastatic, renal, cell,...           317  \n",
       "2  [Chief, Complaint, :, 24, Hour, Events, :, -, ...          1135  \n",
       "3  [Chief, Complaint, :, Acute, Hepatitis, HPI, :...          1976  \n",
       "4  [Chief, Complaint, :, HPI, :, 24, Hour, Events...           567  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# skip\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip\n",
    "df.to_csv('NOTEEVENTS_tokenized.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chief',\n",
       " 'Complaint',\n",
       " ':',\n",
       " '24',\n",
       " 'Hour',\n",
       " 'Events',\n",
       " ':',\n",
       " '-',\n",
       " 'Pericardiocenesis',\n",
       " 'performed',\n",
       " ';',\n",
       " '250',\n",
       " 'cc',\n",
       " 'of',\n",
       " 'serosanguinous',\n",
       " 'fluid',\n",
       " 'removed',\n",
       " '.',\n",
       " 'Sheath',\n",
       " 'pulled',\n",
       " '.',\n",
       " 'TotProt',\n",
       " ':',\n",
       " '5.2',\n",
       " '.',\n",
       " 'Glucose',\n",
       " ':',\n",
       " '57',\n",
       " '.',\n",
       " 'LD',\n",
       " '(',\n",
       " 'LDH',\n",
       " ')',\n",
       " ':',\n",
       " '1303',\n",
       " '.',\n",
       " 'Amylase',\n",
       " ':',\n",
       " '48',\n",
       " '.',\n",
       " 'Albumin',\n",
       " ':',\n",
       " '3.1',\n",
       " '.',\n",
       " 'WBC',\n",
       " ':',\n",
       " '2556',\n",
       " '.',\n",
       " 'Hct',\n",
       " ',',\n",
       " 'Fl',\n",
       " ':',\n",
       " '4',\n",
       " '.',\n",
       " 'Meets',\n",
       " 'exudate',\n",
       " 'criteria',\n",
       " 'by',\n",
       " 'glucose',\n",
       " 'less',\n",
       " 'than',\n",
       " '60',\n",
       " 'and',\n",
       " 'Protein',\n",
       " 'greater',\n",
       " 'than',\n",
       " '3',\n",
       " '.',\n",
       " '-',\n",
       " 'Heparin',\n",
       " 'd/cd',\n",
       " 'given',\n",
       " 'concern',\n",
       " 'it',\n",
       " 'might',\n",
       " 'worsen',\n",
       " 'hemorrhagic',\n",
       " 'effusion',\n",
       " '-',\n",
       " 'RF',\n",
       " '27',\n",
       " '(',\n",
       " 'up',\n",
       " 'from',\n",
       " '[',\n",
       " '*',\n",
       " '*',\n",
       " '2153-2-23',\n",
       " '*',\n",
       " '*',\n",
       " ']',\n",
       " ')',\n",
       " '.',\n",
       " 'TSH',\n",
       " '2.1',\n",
       " '.',\n",
       " 'RF',\n",
       " '27',\n",
       " ';',\n",
       " 'C3',\n",
       " 'and',\n",
       " 'C4',\n",
       " 'pending',\n",
       " '-',\n",
       " 'Post',\n",
       " 'cath',\n",
       " 'check',\n",
       " '8',\n",
       " 'pm',\n",
       " 'unremarkable',\n",
       " '-',\n",
       " 'TTE',\n",
       " 'post',\n",
       " 'procedure',\n",
       " 'showed',\n",
       " 'tiny',\n",
       " 'residual',\n",
       " 'effusion',\n",
       " ',',\n",
       " 'but',\n",
       " 'markedly',\n",
       " 'improved',\n",
       " '.',\n",
       " '-',\n",
       " 'Started',\n",
       " 'Indocin',\n",
       " '-',\n",
       " 'Contact',\n",
       " '[',\n",
       " '*',\n",
       " '*',\n",
       " 'Name',\n",
       " '(',\n",
       " 'NI',\n",
       " ')',\n",
       " '*',\n",
       " '*',\n",
       " ']',\n",
       " 'Rheumatology',\n",
       " 're',\n",
       " ':',\n",
       " 'further',\n",
       " 'management',\n",
       " '-',\n",
       " '11AM',\n",
       " 'Grew-out',\n",
       " 'GPC',\n",
       " 's',\n",
       " 'from',\n",
       " 'pericardial',\n",
       " 'fluid',\n",
       " '.',\n",
       " 'Allergies',\n",
       " ':',\n",
       " 'No',\n",
       " 'Known',\n",
       " 'Drug',\n",
       " 'Allergies',\n",
       " 'Last',\n",
       " 'dose',\n",
       " 'of',\n",
       " 'Antibiotics',\n",
       " ':',\n",
       " 'Infusions',\n",
       " ':',\n",
       " 'Other',\n",
       " 'ICU',\n",
       " 'medications',\n",
       " ':',\n",
       " 'Morphine',\n",
       " 'Sulfate',\n",
       " '-',\n",
       " '[',\n",
       " '*',\n",
       " '*',\n",
       " '2157-4-28',\n",
       " '*',\n",
       " '*',\n",
       " ']',\n",
       " '10:30',\n",
       " 'PM',\n",
       " 'Other',\n",
       " 'medications',\n",
       " ':',\n",
       " 'Changes',\n",
       " 'to',\n",
       " 'medical',\n",
       " 'and',\n",
       " 'family',\n",
       " 'history',\n",
       " ':',\n",
       " 'Review',\n",
       " 'of',\n",
       " 'systems',\n",
       " 'is',\n",
       " 'unchanged',\n",
       " 'from',\n",
       " 'admission',\n",
       " 'except',\n",
       " 'as',\n",
       " 'noted',\n",
       " 'below',\n",
       " 'Review',\n",
       " 'of',\n",
       " 'systems',\n",
       " ':',\n",
       " 'Chest',\n",
       " 'pain',\n",
       " 'improved',\n",
       " 'overall',\n",
       " ',',\n",
       " 'although',\n",
       " 'still',\n",
       " 'present',\n",
       " 'with',\n",
       " 'deep',\n",
       " 'respiration',\n",
       " 'or',\n",
       " 'movement',\n",
       " '.',\n",
       " 'Flowsheet',\n",
       " 'Data',\n",
       " 'as',\n",
       " 'of',\n",
       " '[',\n",
       " '*',\n",
       " '*',\n",
       " '2157-4-29',\n",
       " '*',\n",
       " '*',\n",
       " ']',\n",
       " '07:11',\n",
       " 'AM',\n",
       " 'Vital',\n",
       " 'signs',\n",
       " 'Hemodynamic',\n",
       " 'monitoring',\n",
       " 'Fluid',\n",
       " 'balance',\n",
       " '24',\n",
       " 'hours',\n",
       " 'Since',\n",
       " '12',\n",
       " 'AM',\n",
       " 'Tmax',\n",
       " ':',\n",
       " '37.4',\n",
       " 'C',\n",
       " '(',\n",
       " '99.4',\n",
       " 'Tcurrent',\n",
       " ':',\n",
       " '36.4',\n",
       " 'C',\n",
       " '(',\n",
       " '97.6',\n",
       " 'HR',\n",
       " ':',\n",
       " '85',\n",
       " '(',\n",
       " '85',\n",
       " '-',\n",
       " '107',\n",
       " ')',\n",
       " 'bpm',\n",
       " 'BP',\n",
       " ':',\n",
       " '82/54',\n",
       " '(',\n",
       " '60',\n",
       " ')',\n",
       " '{',\n",
       " '80/50',\n",
       " '(',\n",
       " '36',\n",
       " ')',\n",
       " '-',\n",
       " '115/72',\n",
       " '(',\n",
       " '80',\n",
       " ')',\n",
       " '}',\n",
       " 'mmHg',\n",
       " 'RR',\n",
       " ':',\n",
       " '16',\n",
       " '(',\n",
       " '13',\n",
       " '-',\n",
       " '26',\n",
       " ')',\n",
       " 'insp/min',\n",
       " 'SpO2',\n",
       " ':',\n",
       " '95',\n",
       " '%',\n",
       " 'Heart',\n",
       " 'rhythm',\n",
       " ':',\n",
       " 'SR',\n",
       " '(',\n",
       " 'Sinus',\n",
       " 'Rhythm',\n",
       " ')',\n",
       " 'Wgt',\n",
       " '(',\n",
       " 'current',\n",
       " ')',\n",
       " ':',\n",
       " '55',\n",
       " 'kg',\n",
       " '(',\n",
       " 'admission',\n",
       " ')',\n",
       " ':',\n",
       " '55',\n",
       " 'kg',\n",
       " 'Height',\n",
       " ':',\n",
       " '64',\n",
       " 'Inch',\n",
       " 'Total',\n",
       " 'In',\n",
       " ':',\n",
       " '1,998',\n",
       " 'mL',\n",
       " 'PO',\n",
       " ':',\n",
       " '420',\n",
       " 'mL',\n",
       " 'TF',\n",
       " ':',\n",
       " 'IVF',\n",
       " ':',\n",
       " '1,578',\n",
       " 'mL',\n",
       " 'Blood',\n",
       " 'products',\n",
       " ':',\n",
       " 'Total',\n",
       " 'out',\n",
       " ':',\n",
       " '2,020',\n",
       " 'mL',\n",
       " '0',\n",
       " 'mL',\n",
       " 'Urine',\n",
       " ':',\n",
       " '1,860',\n",
       " 'mL',\n",
       " 'NG',\n",
       " ':',\n",
       " 'Stool',\n",
       " ':',\n",
       " 'Drains',\n",
       " ':',\n",
       " '160',\n",
       " 'mL',\n",
       " 'Balance',\n",
       " ':',\n",
       " '-23',\n",
       " 'mL',\n",
       " '0',\n",
       " 'mL',\n",
       " 'Respiratory',\n",
       " 'support',\n",
       " 'O2',\n",
       " 'Delivery',\n",
       " 'Device',\n",
       " ':',\n",
       " 'None',\n",
       " 'SpO2',\n",
       " ':',\n",
       " '95',\n",
       " '%',\n",
       " 'ABG',\n",
       " ':',\n",
       " '////',\n",
       " 'Physical',\n",
       " 'Examination',\n",
       " 'General',\n",
       " '-',\n",
       " 'Resting',\n",
       " 'comfortably',\n",
       " 'in',\n",
       " 'bed',\n",
       " ',',\n",
       " 'no',\n",
       " 'acute',\n",
       " 'distress',\n",
       " 'HEENT',\n",
       " '-',\n",
       " 'Sclera',\n",
       " 'anicteric',\n",
       " ',',\n",
       " 'MMM',\n",
       " ',',\n",
       " 'oropharynx',\n",
       " 'clear',\n",
       " 'Neck',\n",
       " '-',\n",
       " 'JVD',\n",
       " 'to',\n",
       " 'angle',\n",
       " 'of',\n",
       " 'mandible',\n",
       " 'at',\n",
       " '~30',\n",
       " 'degrees',\n",
       " ';',\n",
       " 'positive',\n",
       " 'hepatojugular',\n",
       " 'reflex',\n",
       " ';',\n",
       " 'increased',\n",
       " 'JVP',\n",
       " 'with',\n",
       " 'deep',\n",
       " 'respiration',\n",
       " 'Pulm',\n",
       " '-',\n",
       " 'CTA',\n",
       " 'bilaterally',\n",
       " ';',\n",
       " 'no',\n",
       " 'wheezes',\n",
       " ',',\n",
       " 'rales',\n",
       " ',',\n",
       " 'or',\n",
       " 'rhonchi',\n",
       " 'CV',\n",
       " '-',\n",
       " 'Decreased',\n",
       " 'breath',\n",
       " 'sounds',\n",
       " ';',\n",
       " 'tachycardic',\n",
       " ';',\n",
       " 'normal',\n",
       " 'S1/S2',\n",
       " ';',\n",
       " 'no',\n",
       " 'murmurs',\n",
       " ';',\n",
       " 'no',\n",
       " 'appreciable',\n",
       " 'pericardial',\n",
       " 'rub',\n",
       " ';',\n",
       " '?',\n",
       " 'rub',\n",
       " 'with',\n",
       " 'inspiratory',\n",
       " 'variation',\n",
       " ';',\n",
       " 'pulsus',\n",
       " '10',\n",
       " 'Abdomen',\n",
       " '-',\n",
       " 'Normoactive',\n",
       " 'bowel',\n",
       " 'sounds',\n",
       " ';',\n",
       " 'soft',\n",
       " ',',\n",
       " 'non-tender',\n",
       " ',',\n",
       " 'non-distended',\n",
       " 'Ext',\n",
       " '-',\n",
       " 'Warm',\n",
       " ',',\n",
       " 'well',\n",
       " 'perfused',\n",
       " ',',\n",
       " 'radial',\n",
       " 'and',\n",
       " 'DP',\n",
       " 'pulses',\n",
       " '2+',\n",
       " ';',\n",
       " 'no',\n",
       " 'edema',\n",
       " 'Labs',\n",
       " '/',\n",
       " 'Radiology',\n",
       " '358',\n",
       " 'K/uL',\n",
       " '10.0',\n",
       " 'g/dL',\n",
       " '95',\n",
       " 'mg/dL',\n",
       " '0.7',\n",
       " 'mg/dL',\n",
       " '23',\n",
       " 'mEq/L',\n",
       " '3.9',\n",
       " 'mEq/L',\n",
       " '14',\n",
       " 'mg/dL',\n",
       " '105',\n",
       " 'mEq/L',\n",
       " '139',\n",
       " 'mEq/L',\n",
       " '29.5',\n",
       " '%',\n",
       " '8.1',\n",
       " 'K/uL',\n",
       " '[',\n",
       " 'image002.jpg',\n",
       " ']',\n",
       " 'Labs',\n",
       " 'from',\n",
       " '[',\n",
       " '*',\n",
       " '*',\n",
       " '2157-4-27',\n",
       " '*',\n",
       " '*',\n",
       " ']',\n",
       " '.',\n",
       " 'Labs',\n",
       " 'from',\n",
       " '[',\n",
       " '*',\n",
       " '*',\n",
       " '2157-4-28',\n",
       " '*',\n",
       " '*',\n",
       " ']',\n",
       " 'reviewed',\n",
       " '.',\n",
       " 'WBC',\n",
       " 'count',\n",
       " ',',\n",
       " 'hematocrit',\n",
       " ',',\n",
       " 'and',\n",
       " 'creatinine',\n",
       " 'stable',\n",
       " '.',\n",
       " 'Paracentesis',\n",
       " 'fluid',\n",
       " ':',\n",
       " 'WBC',\n",
       " ':',\n",
       " '2556',\n",
       " 'Hct',\n",
       " ',',\n",
       " 'Fl',\n",
       " ':',\n",
       " '4',\n",
       " 'Polys',\n",
       " ':',\n",
       " '34',\n",
       " 'Lymphs',\n",
       " ':',\n",
       " '39',\n",
       " 'Monos',\n",
       " ':',\n",
       " '12',\n",
       " 'Eos',\n",
       " ':',\n",
       " '3',\n",
       " 'Macro',\n",
       " ':',\n",
       " '12',\n",
       " 'TotProt',\n",
       " ':',\n",
       " '5.2',\n",
       " 'Glucose',\n",
       " ':',\n",
       " '57',\n",
       " 'LD',\n",
       " '(',\n",
       " 'LDH',\n",
       " ')',\n",
       " ':',\n",
       " '1303',\n",
       " 'Amylase',\n",
       " ':',\n",
       " '48',\n",
       " 'Albumin',\n",
       " ':',\n",
       " '3.1',\n",
       " '[',\n",
       " '*',\n",
       " '*',\n",
       " '2157-4-28',\n",
       " '*',\n",
       " '*',\n",
       " ']',\n",
       " '05:07',\n",
       " 'AM',\n",
       " '[',\n",
       " '*',\n",
       " '*',\n",
       " '2157-4-28',\n",
       " '*',\n",
       " '*',\n",
       " ']',\n",
       " '01:46',\n",
       " 'PM',\n",
       " 'WBC',\n",
       " '8.1',\n",
       " 'Hct',\n",
       " '29.3',\n",
       " '29.5',\n",
       " 'Plt',\n",
       " '358',\n",
       " 'Cr',\n",
       " '0.7',\n",
       " 'TropT',\n",
       " '<',\n",
       " '0.01',\n",
       " 'Glucose',\n",
       " '95',\n",
       " 'Other',\n",
       " 'labs',\n",
       " ':',\n",
       " 'PT',\n",
       " '/',\n",
       " 'PTT',\n",
       " '/',\n",
       " 'INR:13.6/26.8/1.2',\n",
       " ',',\n",
       " 'CK',\n",
       " '/',\n",
       " 'CKMB',\n",
       " '/',\n",
       " 'Troponin-T:53//',\n",
       " '<',\n",
       " '0.01',\n",
       " ',',\n",
       " 'Differential-Neuts:73.2',\n",
       " '%',\n",
       " ',',\n",
       " 'Lymph:17.4',\n",
       " '%',\n",
       " ',',\n",
       " 'Mono:5.5',\n",
       " '%',\n",
       " ',',\n",
       " 'Eos:3.6',\n",
       " '%',\n",
       " ',',\n",
       " 'Albumin:3.8',\n",
       " 'g/dL',\n",
       " ',',\n",
       " 'LDH:223',\n",
       " 'IU/L',\n",
       " ',',\n",
       " 'Ca++:9.2',\n",
       " 'mg/dL',\n",
       " ',',\n",
       " 'Mg++:1.8',\n",
       " 'mg/dL',\n",
       " ',',\n",
       " 'PO4:3.4',\n",
       " 'mg/dL',\n",
       " 'TTE',\n",
       " '(',\n",
       " '[',\n",
       " '*',\n",
       " '*',\n",
       " '2157-4-28',\n",
       " '*',\n",
       " '*',\n",
       " ']',\n",
       " ')',\n",
       " ':',\n",
       " 'Overall',\n",
       " 'left',\n",
       " 'ventricular',\n",
       " 'systolic',\n",
       " 'function',\n",
       " 'is',\n",
       " 'normal',\n",
       " '(',\n",
       " 'LVEF',\n",
       " '>',\n",
       " '55',\n",
       " '%',\n",
       " ')',\n",
       " '.',\n",
       " 'Right',\n",
       " 'ventricular',\n",
       " 'chamber',\n",
       " 'size',\n",
       " 'and',\n",
       " 'free',\n",
       " 'wall',\n",
       " 'motion',\n",
       " 'are',\n",
       " 'normal',\n",
       " '.',\n",
       " 'The',\n",
       " 'mitral',\n",
       " 'valve',\n",
       " 'leaflets',\n",
       " 'are',\n",
       " 'mildly',\n",
       " 'thickened',\n",
       " '.',\n",
       " 'There',\n",
       " 'is',\n",
       " 'a',\n",
       " 'trivial/physiologic',\n",
       " 'pericardial',\n",
       " 'effusion',\n",
       " '.',\n",
       " 'A',\n",
       " 'catheter',\n",
       " 'is',\n",
       " 'seen',\n",
       " 'in',\n",
       " 'the',\n",
       " 'pericardial',\n",
       " 'space',\n",
       " '.',\n",
       " 'There',\n",
       " 'are',\n",
       " 'no',\n",
       " 'echocardiographic',\n",
       " 'signs',\n",
       " 'of',\n",
       " 'tamponade',\n",
       " '.',\n",
       " 'IMPRESSION',\n",
       " ':',\n",
       " 'Tiny',\n",
       " 'residual',\n",
       " 'effusion',\n",
       " 'post',\n",
       " 'tap',\n",
       " '.',\n",
       " 'No',\n",
       " 'evidence',\n",
       " 'of',\n",
       " 'tamponade',\n",
       " 'physiology',\n",
       " '.',\n",
       " 'Assessment',\n",
       " 'and',\n",
       " 'Plan',\n",
       " '53F',\n",
       " 'with',\n",
       " 'RA',\n",
       " 'on',\n",
       " 'DMARDs',\n",
       " ',',\n",
       " 'history',\n",
       " 'of',\n",
       " 'positive',\n",
       " 'PPD',\n",
       " 's/p',\n",
       " 'INH',\n",
       " 'treatment',\n",
       " 'admitted',\n",
       " 'with',\n",
       " 'pericardial',\n",
       " 'effusion',\n",
       " 'without',\n",
       " 'tamponade',\n",
       " 'physiology',\n",
       " '.',\n",
       " 'Now',\n",
       " 'growing',\n",
       " 'out',\n",
       " 'GPC',\n",
       " 'on',\n",
       " 'pericardial',\n",
       " 'fluid',\n",
       " 'culture',\n",
       " '.',\n",
       " '#',\n",
       " '.',\n",
       " 'Pericardial',\n",
       " 'effusion',\n",
       " ':',\n",
       " 'Fluid',\n",
       " 'consistent',\n",
       " 'with',\n",
       " 'exudate',\n",
       " ';',\n",
       " 'also',\n",
       " 'sanguinous',\n",
       " '.',\n",
       " 'Given',\n",
       " 'exudative',\n",
       " 'and',\n",
       " 'with',\n",
       " 'low',\n",
       " 'glucose',\n",
       " ',',\n",
       " 'secondary',\n",
       " 'to',\n",
       " 'RA',\n",
       " '.',\n",
       " 'Treatment',\n",
       " 'for',\n",
       " 'this',\n",
       " 'is',\n",
       " 'steroid',\n",
       " 'therapy',\n",
       " ',',\n",
       " 'although',\n",
       " 'patient',\n",
       " 'with',\n",
       " 'postive',\n",
       " 'pericardial',\n",
       " 'fluid',\n",
       " 'culture',\n",
       " 'given',\n",
       " 'that',\n",
       " 'she',\n",
       " 'is',\n",
       " 'afebrile',\n",
       " ',',\n",
       " 'without',\n",
       " 'leukocytosis',\n",
       " 'or',\n",
       " 'left',\n",
       " 'shift',\n",
       " ',',\n",
       " 'and',\n",
       " 'overall',\n",
       " 'feeling',\n",
       " 'well',\n",
       " ',',\n",
       " 'this',\n",
       " 'is',\n",
       " 'likely',\n",
       " 'a',\n",
       " 'contaminant',\n",
       " '.',\n",
       " 'Drainage',\n",
       " 'as',\n",
       " 'tapered',\n",
       " 'off',\n",
       " ';',\n",
       " '<',\n",
       " '50cc',\n",
       " 'since',\n",
       " 'placement',\n",
       " 'approximately',\n",
       " '20',\n",
       " 'hours',\n",
       " 'ago',\n",
       " '.',\n",
       " 'Still',\n",
       " 'with',\n",
       " 'distended',\n",
       " 'neck',\n",
       " 'veins',\n",
       " ',',\n",
       " 'low',\n",
       " 'BP',\n",
       " '(',\n",
       " 'likely',\n",
       " 'her',\n",
       " 'baseline',\n",
       " ')',\n",
       " '.',\n",
       " '-',\n",
       " 'Rheumatology',\n",
       " 'consult',\n",
       " '-',\n",
       " 'Consider',\n",
       " 'steroid',\n",
       " 'therapy',\n",
       " '-',\n",
       " 'Await',\n",
       " 'speciation',\n",
       " 'of',\n",
       " 'GPC',\n",
       " ';',\n",
       " 'if',\n",
       " 'coag',\n",
       " 'positive',\n",
       " ',',\n",
       " 'will',\n",
       " 'need',\n",
       " 'treatment',\n",
       " '-',\n",
       " 'Close',\n",
       " 'monitor',\n",
       " 'of',\n",
       " 'hemodynamics',\n",
       " '-',\n",
       " 'Pull',\n",
       " 'drain',\n",
       " 'this',\n",
       " 'afternoon',\n",
       " '#',\n",
       " '.',\n",
       " 'Anemia',\n",
       " ':',\n",
       " 'Hematocrit',\n",
       " 'stable',\n",
       " '.',\n",
       " 'Within',\n",
       " 'past',\n",
       " '6',\n",
       " 'months',\n",
       " ',',\n",
       " 'ranging',\n",
       " 'between',\n",
       " '36-39',\n",
       " '.',\n",
       " 'No',\n",
       " 'evidence',\n",
       " 'of',\n",
       " 'bleeding',\n",
       " 'or',\n",
       " 'reason',\n",
       " 'for',\n",
       " 'hemolysis',\n",
       " '.',\n",
       " 'Unclear',\n",
       " 'if',\n",
       " 'hemodilutional',\n",
       " ',',\n",
       " 'although',\n",
       " 'unlikely',\n",
       " 'given',\n",
       " 'that',\n",
       " 'isolated',\n",
       " 'cell',\n",
       " 'line',\n",
       " 'down',\n",
       " '.',\n",
       " 'Even',\n",
       " 'if',\n",
       " 'above',\n",
       " 'effusion',\n",
       " 'is',\n",
       " 'hemorrhagic',\n",
       " ',',\n",
       " 'would',\n",
       " 'not',\n",
       " 'expect',\n",
       " 'such',\n",
       " 'a',\n",
       " 'significant',\n",
       " 'hematocrit',\n",
       " 'drop',\n",
       " '(',\n",
       " 'pericardium',\n",
       " 'likely',\n",
       " 'can',\n",
       " 'not',\n",
       " 'hold',\n",
       " 'this',\n",
       " 'quantity',\n",
       " 'of',\n",
       " 'blood',\n",
       " ')',\n",
       " '.',\n",
       " '-',\n",
       " 'Continue',\n",
       " 'folic',\n",
       " 'acid',\n",
       " 'per',\n",
       " 'home',\n",
       " 'regimen',\n",
       " '-',\n",
       " 'Retics',\n",
       " ',',\n",
       " 'LDH',\n",
       " ',',\n",
       " 'Hapto',\n",
       " ',',\n",
       " 'Iron',\n",
       " 'studies',\n",
       " ',',\n",
       " 'Gc',\n",
       " 'stool',\n",
       " 'times',\n",
       " 'three',\n",
       " '#',\n",
       " '.',\n",
       " 'Fever',\n",
       " ':',\n",
       " 'Resolved',\n",
       " '.',\n",
       " '#',\n",
       " '.',\n",
       " 'Acute',\n",
       " 'kidney',\n",
       " 'injury',\n",
       " ':',\n",
       " 'Resolved',\n",
       " '.',\n",
       " 'Likely',\n",
       " 'prerenal',\n",
       " '.',\n",
       " '#',\n",
       " '.',\n",
       " ...]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# skip\n",
    "df['tokenized_sents'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up tokenized sentences - remove punctuations and stop words and lower casr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip\n",
    "df = pd.read_csv('./NOTEEVENTS_tokenized.csv') #all notes as df tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip #lowercasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip\n",
    "df['lower_tokens'] = df['tokenized_sents'].map(lambda x: x.lower() if isinstance(x,str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# skip\n",
    "type(df['tokenized_sents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip\n",
    "df['lower_tokens'] = df['tokenized_sents'].map(lambda x: x if type(x)!=str else x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized_sents</th>\n",
       "      <th>sents_length</th>\n",
       "      <th>lower_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76 y/o M initially admitted to [**Hospital3 33...</td>\n",
       "      <td>['76', 'y/o', 'M', 'initially', 'admitted', 't...</td>\n",
       "      <td>901</td>\n",
       "      <td>['76', 'y/o', 'm', 'initially', 'admitted', 't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54yr man with hx metastatic renal cell ca, c/o...</td>\n",
       "      <td>['54yr', 'man', 'with', 'hx', 'metastatic', 'r...</td>\n",
       "      <td>317</td>\n",
       "      <td>['54yr', 'man', 'with', 'hx', 'metastatic', 'r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chief Complaint:\\n   24 Hour Events:\\n   - Per...</td>\n",
       "      <td>['Chief', 'Complaint', ':', '24', 'Hour', 'Eve...</td>\n",
       "      <td>1135</td>\n",
       "      <td>['chief', 'complaint', ':', '24', 'hour', 'eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chief Complaint:  Acute Hepatitis\\n   HPI:\\n  ...</td>\n",
       "      <td>['Chief', 'Complaint', ':', 'Acute', 'Hepatiti...</td>\n",
       "      <td>1976</td>\n",
       "      <td>['chief', 'complaint', ':', 'acute', 'hepatiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chief Complaint:\\n   HPI:\\n   24 Hour Events:\\...</td>\n",
       "      <td>['Chief', 'Complaint', ':', 'HPI', ':', '24', ...</td>\n",
       "      <td>567</td>\n",
       "      <td>['chief', 'complaint', ':', 'hpi', ':', '24', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  76 y/o M initially admitted to [**Hospital3 33...   \n",
       "1  54yr man with hx metastatic renal cell ca, c/o...   \n",
       "2  Chief Complaint:\\n   24 Hour Events:\\n   - Per...   \n",
       "3  Chief Complaint:  Acute Hepatitis\\n   HPI:\\n  ...   \n",
       "4  Chief Complaint:\\n   HPI:\\n   24 Hour Events:\\...   \n",
       "\n",
       "                                     tokenized_sents  sents_length  \\\n",
       "0  ['76', 'y/o', 'M', 'initially', 'admitted', 't...           901   \n",
       "1  ['54yr', 'man', 'with', 'hx', 'metastatic', 'r...           317   \n",
       "2  ['Chief', 'Complaint', ':', '24', 'Hour', 'Eve...          1135   \n",
       "3  ['Chief', 'Complaint', ':', 'Acute', 'Hepatiti...          1976   \n",
       "4  ['Chief', 'Complaint', ':', 'HPI', ':', '24', ...           567   \n",
       "\n",
       "                                        lower_tokens  \n",
       "0  ['76', 'y/o', 'm', 'initially', 'admitted', 't...  \n",
       "1  ['54yr', 'man', 'with', 'hx', 'metastatic', 'r...  \n",
       "2  ['chief', 'complaint', ':', '24', 'hour', 'eve...  \n",
       "3  ['chief', 'complaint', ':', 'acute', 'hepatiti...  \n",
       "4  ['chief', 'complaint', ':', 'hpi', ':', '24', ...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# skip\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip\n",
    "df['lower_tokens'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove punctuations and only keep alphanumericals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "# skip\n",
    "import string\n",
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip\n",
    "df['lower_no_punc_tokens']=df['lower_tokens'].replace(':','',regex=True) #this works but only one punctuation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip\n",
    "df['lower_no_punc_tokens']=df['lower_tokens'].replace('[!#$%&()*+,-./:;<=>?@[\\]^_`{|}~]','',regex=True) #this works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized_sents</th>\n",
       "      <th>sents_length</th>\n",
       "      <th>lower_tokens</th>\n",
       "      <th>lower_no_punc_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76 y/o M initially admitted to [**Hospital3 33...</td>\n",
       "      <td>['76', 'y/o', 'M', 'initially', 'admitted', 't...</td>\n",
       "      <td>901</td>\n",
       "      <td>['76', 'y/o', 'm', 'initially', 'admitted', 't...</td>\n",
       "      <td>'76' 'yo' 'm' 'initially' 'admitted' 'to' '' '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54yr man with hx metastatic renal cell ca, c/o...</td>\n",
       "      <td>['54yr', 'man', 'with', 'hx', 'metastatic', 'r...</td>\n",
       "      <td>317</td>\n",
       "      <td>['54yr', 'man', 'with', 'hx', 'metastatic', 'r...</td>\n",
       "      <td>'54yr' 'man' 'with' 'hx' 'metastatic' 'renal' ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chief Complaint:\\n   24 Hour Events:\\n   - Per...</td>\n",
       "      <td>['Chief', 'Complaint', ':', '24', 'Hour', 'Eve...</td>\n",
       "      <td>1135</td>\n",
       "      <td>['chief', 'complaint', ':', '24', 'hour', 'eve...</td>\n",
       "      <td>'chief' 'complaint' '' '24' 'hour' 'events' ''...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chief Complaint:  Acute Hepatitis\\n   HPI:\\n  ...</td>\n",
       "      <td>['Chief', 'Complaint', ':', 'Acute', 'Hepatiti...</td>\n",
       "      <td>1976</td>\n",
       "      <td>['chief', 'complaint', ':', 'acute', 'hepatiti...</td>\n",
       "      <td>'chief' 'complaint' '' 'acute' 'hepatitis' 'hp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chief Complaint:\\n   HPI:\\n   24 Hour Events:\\...</td>\n",
       "      <td>['Chief', 'Complaint', ':', 'HPI', ':', '24', ...</td>\n",
       "      <td>567</td>\n",
       "      <td>['chief', 'complaint', ':', 'hpi', ':', '24', ...</td>\n",
       "      <td>'chief' 'complaint' '' 'hpi' '' '24' 'hour' 'e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  76 y/o M initially admitted to [**Hospital3 33...   \n",
       "1  54yr man with hx metastatic renal cell ca, c/o...   \n",
       "2  Chief Complaint:\\n   24 Hour Events:\\n   - Per...   \n",
       "3  Chief Complaint:  Acute Hepatitis\\n   HPI:\\n  ...   \n",
       "4  Chief Complaint:\\n   HPI:\\n   24 Hour Events:\\...   \n",
       "\n",
       "                                     tokenized_sents  sents_length  \\\n",
       "0  ['76', 'y/o', 'M', 'initially', 'admitted', 't...           901   \n",
       "1  ['54yr', 'man', 'with', 'hx', 'metastatic', 'r...           317   \n",
       "2  ['Chief', 'Complaint', ':', '24', 'Hour', 'Eve...          1135   \n",
       "3  ['Chief', 'Complaint', ':', 'Acute', 'Hepatiti...          1976   \n",
       "4  ['Chief', 'Complaint', ':', 'HPI', ':', '24', ...           567   \n",
       "\n",
       "                                        lower_tokens  \\\n",
       "0  ['76', 'y/o', 'm', 'initially', 'admitted', 't...   \n",
       "1  ['54yr', 'man', 'with', 'hx', 'metastatic', 'r...   \n",
       "2  ['chief', 'complaint', ':', '24', 'hour', 'eve...   \n",
       "3  ['chief', 'complaint', ':', 'acute', 'hepatiti...   \n",
       "4  ['chief', 'complaint', ':', 'hpi', ':', '24', ...   \n",
       "\n",
       "                                lower_no_punc_tokens  \n",
       "0  '76' 'yo' 'm' 'initially' 'admitted' 'to' '' '...  \n",
       "1  '54yr' 'man' 'with' 'hx' 'metastatic' 'renal' ...  \n",
       "2  'chief' 'complaint' '' '24' 'hour' 'events' ''...  \n",
       "3  'chief' 'complaint' '' 'acute' 'hepatitis' 'hp...  \n",
       "4  'chief' 'complaint' '' 'hpi' '' '24' 'hour' 'e...  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# skip\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'chief' 'complaint' '' '24' 'hour' 'events' '' '' 'pericardiocenesis' 'performed' '' '250' 'cc' 'of' 'serosanguinous' 'fluid' 'removed' '' 'sheath' 'pulled' '' 'totprot' '' '52' '' 'glucose' '' '57' '' 'ld' '' 'ldh' '' '' '1303' '' 'amylase' '' '48' '' 'albumin' '' '31' '' 'wbc' '' '2556' '' 'hct' '' 'fl' '' '4' '' 'meets' 'exudate' 'criteria' 'by' 'glucose' 'less' 'than' '60' 'and' 'protein' 'greater' 'than' '3' '' '' 'heparin' 'dcd' 'given' 'concern' 'it' 'might' 'worsen' 'hemorrhagic' 'effusion' '' 'rf' '27' '' 'up' 'from' '' '' '' '2153223' '' '' '' '' '' 'tsh' '21' '' 'rf' '27' '' 'c3' 'and' 'c4' 'pending' '' 'post' 'cath' 'check' '8' 'pm' 'unremarkable' '' 'tte' 'post' 'procedure' 'showed' 'tiny' 'residual' 'effusion' '' 'but' 'markedly' 'improved' '' '' 'started' 'indocin' '' 'contact' '' '' '' 'name' '' 'ni' '' '' '' '' 'rheumatology' 're' '' 'further' 'management' '' '11am' 'grewout' 'gpc' 's' 'from' 'pericardial' 'fluid' '' 'allergies' '' 'no' 'known' 'drug' 'allergies' 'last' 'dose' 'of' 'antibiotics' '' 'infusions' '' 'other' 'icu' 'medications' '' 'morphine' 'sulfate' '' '' '' '' '2157428' '' '' '' '1030' 'pm' 'other' 'medications' '' 'changes' 'to' 'medical' 'and' 'family' 'history' '' 'review' 'of' 'systems' 'is' 'unchanged' 'from' 'admission' 'except' 'as' 'noted' 'below' 'review' 'of' 'systems' '' 'chest' 'pain' 'improved' 'overall' '' 'although' 'still' 'present' 'with' 'deep' 'respiration' 'or' 'movement' '' 'flowsheet' 'data' 'as' 'of' '' '' '' '2157429' '' '' '' '0711' 'am' 'vital' 'signs' 'hemodynamic' 'monitoring' 'fluid' 'balance' '24' 'hours' 'since' '12' 'am' 'tmax' '' '374' 'c' '' '994' 'tcurrent' '' '364' 'c' '' '976' 'hr' '' '85' '' '85' '' '107' '' 'bpm' 'bp' '' '8254' '' '60' '' '' '8050' '' '36' '' '' '11572' '' '80' '' '' 'mmhg' 'rr' '' '16' '' '13' '' '26' '' 'inspmin' 'spo2' '' '95' '' 'heart' 'rhythm' '' 'sr' '' 'sinus' 'rhythm' '' 'wgt' '' 'current' '' '' '55' 'kg' '' 'admission' '' '' '55' 'kg' 'height' '' '64' 'inch' 'total' 'in' '' '1998' 'ml' 'po' '' '420' 'ml' 'tf' '' 'ivf' '' '1578' 'ml' 'blood' 'products' '' 'total' 'out' '' '2020' 'ml' '0' 'ml' 'urine' '' '1860' 'ml' 'ng' '' 'stool' '' 'drains' '' '160' 'ml' 'balance' '' '23' 'ml' '0' 'ml' 'respiratory' 'support' 'o2' 'delivery' 'device' '' 'none' 'spo2' '' '95' '' 'abg' '' '' 'physical' 'examination' 'general' '' 'resting' 'comfortably' 'in' 'bed' '' 'no' 'acute' 'distress' 'heent' '' 'sclera' 'anicteric' '' 'mmm' '' 'oropharynx' 'clear' 'neck' '' 'jvd' 'to' 'angle' 'of' 'mandible' 'at' '30' 'degrees' '' 'positive' 'hepatojugular' 'reflex' '' 'increased' 'jvp' 'with' 'deep' 'respiration' 'pulm' '' 'cta' 'bilaterally' '' 'no' 'wheezes' '' 'rales' '' 'or' 'rhonchi' 'cv' '' 'decreased' 'breath' 'sounds' '' 'tachycardic' '' 'normal' 's1s2' '' 'no' 'murmurs' '' 'no' 'appreciable' 'pericardial' 'rub' '' '' 'rub' 'with' 'inspiratory' 'variation' '' 'pulsus' '10' 'abdomen' '' 'normoactive' 'bowel' 'sounds' '' 'soft' '' 'nontender' '' 'nondistended' 'ext' '' 'warm' '' 'well' 'perfused' '' 'radial' 'and' 'dp' 'pulses' '2' '' 'no' 'edema' 'labs' '' 'radiology' '358' 'kul' '100' 'gdl' '95' 'mgdl' '07' 'mgdl' '23' 'meql' '39' 'meql' '14' 'mgdl' '105' 'meql' '139' 'meql' '295' '' '81' 'kul' '' 'image002jpg' '' 'labs' 'from' '' '' '' '2157427' '' '' '' '' 'labs' 'from' '' '' '' '2157428' '' '' '' 'reviewed' '' 'wbc' 'count' '' 'hematocrit' '' 'and' 'creatinine' 'stable' '' 'paracentesis' 'fluid' '' 'wbc' '' '2556' 'hct' '' 'fl' '' '4' 'polys' '' '34' 'lymphs' '' '39' 'monos' '' '12' 'eos' '' '3' 'macro' '' '12' 'totprot' '' '52' 'glucose' '' '57' 'ld' '' 'ldh' '' '' '1303' 'amylase' '' '48' 'albumin' '' '31' '' '' '' '2157428' '' '' '' '0507' 'am' '' '' '' '2157428' '' '' '' '0146' 'pm' 'wbc' '81' 'hct' '293' '295' 'plt' '358' 'cr' '07' 'tropt' '' '001' 'glucose' '95' 'other' 'labs' '' 'pt' '' 'ptt' '' 'inr13626812' '' 'ck' '' 'ckmb' '' 'troponint53' '' '001' '' 'differentialneuts732' '' '' 'lymph174' '' '' 'mono55' '' '' 'eos36' '' '' 'albumin38' 'gdl' '' 'ldh223' 'iul' '' 'ca92' 'mgdl' '' 'mg18' 'mgdl' '' 'po434' 'mgdl' 'tte' '' '' '' '' '2157428' '' '' '' '' '' 'overall' 'left' 'ventricular' 'systolic' 'function' 'is' 'normal' '' 'lvef' '' '55' '' '' '' 'right' 'ventricular' 'chamber' 'size' 'and' 'free' 'wall' 'motion' 'are' 'normal' '' 'the' 'mitral' 'valve' 'leaflets' 'are' 'mildly' 'thickened' '' 'there' 'is' 'a' 'trivialphysiologic' 'pericardial' 'effusion' '' 'a' 'catheter' 'is' 'seen' 'in' 'the' 'pericardial' 'space' '' 'there' 'are' 'no' 'echocardiographic' 'signs' 'of' 'tamponade' '' 'impression' '' 'tiny' 'residual' 'effusion' 'post' 'tap' '' 'no' 'evidence' 'of' 'tamponade' 'physiology' '' 'assessment' 'and' 'plan' '53f' 'with' 'ra' 'on' 'dmards' '' 'history' 'of' 'positive' 'ppd' 'sp' 'inh' 'treatment' 'admitted' 'with' 'pericardial' 'effusion' 'without' 'tamponade' 'physiology' '' 'now' 'growing' 'out' 'gpc' 'on' 'pericardial' 'fluid' 'culture' '' '' '' 'pericardial' 'effusion' '' 'fluid' 'consistent' 'with' 'exudate' '' 'also' 'sanguinous' '' 'given' 'exudative' 'and' 'with' 'low' 'glucose' '' 'secondary' 'to' 'ra' '' 'treatment' 'for' 'this' 'is' 'steroid' 'therapy' '' 'although' 'patient' 'with' 'postive' 'pericardial' 'fluid' 'culture' 'given' 'that' 'she' 'is' 'afebrile' '' 'without' 'leukocytosis' 'or' 'left' 'shift' '' 'and' 'overall' 'feeling' 'well' '' 'this' 'is' 'likely' 'a' 'contaminant' '' 'drainage' 'as' 'tapered' 'off' '' '' '50cc' 'since' 'placement' 'approximately' '20' 'hours' 'ago' '' 'still' 'with' 'distended' 'neck' 'veins' '' 'low' 'bp' '' 'likely' 'her' 'baseline' '' '' '' 'rheumatology' 'consult' '' 'consider' 'steroid' 'therapy' '' 'await' 'speciation' 'of' 'gpc' '' 'if' 'coag' 'positive' '' 'will' 'need' 'treatment' '' 'close' 'monitor' 'of' 'hemodynamics' '' 'pull' 'drain' 'this' 'afternoon' '' '' 'anemia' '' 'hematocrit' 'stable' '' 'within' 'past' '6' 'months' '' 'ranging' 'between' '3639' '' 'no' 'evidence' 'of' 'bleeding' 'or' 'reason' 'for' 'hemolysis' '' 'unclear' 'if' 'hemodilutional' '' 'although' 'unlikely' 'given' 'that' 'isolated' 'cell' 'line' 'down' '' 'even' 'if' 'above' 'effusion' 'is' 'hemorrhagic' '' 'would' 'not' 'expect' 'such' 'a' 'significant' 'hematocrit' 'drop' '' 'pericardium' 'likely' 'can' 'not' 'hold' 'this' 'quantity' 'of' 'blood' '' '' '' 'continue' 'folic' 'acid' 'per' 'home' 'regimen' '' 'retics' '' 'ldh' '' 'hapto' '' 'iron' 'studies' '' 'gc' 'stool' 'times' 'three' '' '' 'fever' '' 'resolved' '' '' '' 'acute' 'kidney' 'injury' '' 'resolved' '' 'likely' 'prerenal' '' '' '' 'rheumatoid' 'arthritis' '' 'patient' 'denies' 'flares' 'of' 'disease' '' 'disease' 'has' 'been' 'stable' 'since' 'diagnosis' 'in' '' '' '' '2149' '' '' '' '' 'rf' 'now' 'positive' '' '' 'continue' 'plaquenil' 'per' 'home' 'regimen' '' 'discuss' 'with' 'rheumatology' 'if' 'okay' 'to' 'restart' 'methotrexate' '' 'rheum' 'consult' '' 'as' 'above' '' '' 'osteoporosis' '' '' 'continue' 'calcium' '' 'vitamin' 'd' 'per' 'home' 'regimen' '' '' 'chronic' 'pain' '' '' 'continue' 'gabapentin' '' 'amitryptiline' 'per' 'home' 'regimen' 'prophylaxis' '' 'pneumoboots' '' 'ambulation' 'bowel' 'regimen' 'prn' 'no' 'indication' 'for' 'ppi' 'at' 'this' 'time' 'full' 'code' 'icu' 'care' 'nutrition' '' 'glycemic' 'control' '' 'lines' '' '20' 'gauge' '' '' '' '' '2157427' '' '' '' '1124' 'pm' 'prophylaxis' '' 'dvt' '' 'stress' 'ulcer' '' 'vap' '' 'comments' '' 'communication' '' 'comments' '' 'code' 'status' '' 'full' 'code' 'disposition' ''\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# skip\n",
    "df['lower_no_punc_tokens'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skipdf.to_csv('NOTEEVENTS_tokenized_nopunct.csv', index=False)\n",
    "df.to_csv('NOTEEVENTS_tokenized_nopunct.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip\n",
    "df_lower_nopunct_tokens = df['lower_no_punc_tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    '76' 'yo' 'm' 'initially' 'admitted' 'to' '' '...\n",
       "1    '54yr' 'man' 'with' 'hx' 'metastatic' 'renal' ...\n",
       "2    'chief' 'complaint' '' '24' 'hour' 'events' ''...\n",
       "3    'chief' 'complaint' '' 'acute' 'hepatitis' 'hp...\n",
       "4    'chief' 'complaint' '' 'hpi' '' '24' 'hour' 'e...\n",
       "Name: lower_no_punc_tokens, dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# skip\n",
    "df_lower_nopunct_tokens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip\n",
    "df.to_csv('NOTEEVENTS_tokenized__lower_nopunct.csv', index=False) #quite large file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip\n",
    "df.to_csv('NOTEEVENTS_tokenized__lower_nopunct.csv.gz', index=False, compression='gzip') #this works and smaller file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip #remove spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'54yr''man''with''hx''metastatic''renal''cell''ca''''co''sob''''was''admitted''to''stonman''floor''on''''''''hospital''ward''name''''''''''and''sent''to''chest''disease''center''today''''''''426''''''''for''pluroscopy''and''biopsy''''5''liters''was''drained''form''right''lung''ct''placed''''after''procedure''pt''became''hypotensive''requiring''fluid''bolus''''with''only''transient''effect''''pt''transferred''to''tsicu''for''further''monitoring''''cancer''''malignant''neoplasm''''''renal''''kidney''''assessment''''right''pleurex''chest''tube''to''water''seal''for''effusion''related''to''metastatic''ca''''fluctuation''only''with''deep''breath''''scant''air''leak''noted''with''deep''breath''''drainage''of''serosanginous''fluid''''1015cc''per''hour''''right''side''breath''sounds''remain''decreased''''clear''''action''''cxr''taken''q2''hour''ct''assessment''of''function''and''drainage''lung''sound''assessment''q''4''hour''response''''ct''status''is''unchanged''''fluctuation''''minimal''leak''with''deep''breathing''only''''minimal''hourly''drainage''''dressing''is''dry''''intact''''lung''sounds''unchanged''''plan''''continue''to''assess''ct''cxr''results''pending''per''thoracic''''ct''to''remain''in''place''today''''pain''control''''acute''pain''''chronic''pain''''assessment''''right''chest''''flank''pain''rated''''''''2182214''''''''''pain''is''constant''and''dull''and''increases''''''''''422''''''''''with''deep''breathing''''coughing''''and''movement''''action''''q''4''hour''''prn''pain''assessment''''treatment''scheduled''methadone''''tylenol''''and''prn''dilaudid''response''''pain''tolerable''per''patient''response''with''exacerbations''with''activity''''pt''also''tiring''with''activities''plan''''continue''pain''assessment''''treatment''''refer''to''nursing''care''plan''''hypotension''''not''shock''''assessment''''action''''response''''plan'''\""
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# skip\n",
    "df_lower_nopunct_tokens[1].replace(' ','') #this works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2083180"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# skip\n",
    "len(df_lower_nopunct_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip\n",
    "df.to_csv('NOTEEVENTS_tokenized__lower_nopunct.csv.gz', index=False, compression='gzip') #this works and smaller file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove stopwords - can be done using gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip\n",
    "df_clean = pd.read_csv('NOTEEVENTS_tokenized__lower_nopunct.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized_sents</th>\n",
       "      <th>sents_length</th>\n",
       "      <th>lower_tokens</th>\n",
       "      <th>lower_no_punc_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76 y/o M initially admitted to [**Hospital3 33...</td>\n",
       "      <td>['76', 'y/o', 'M', 'initially', 'admitted', 't...</td>\n",
       "      <td>901</td>\n",
       "      <td>['76', 'y/o', 'm', 'initially', 'admitted', 't...</td>\n",
       "      <td>'76' 'yo' 'm' 'initially' 'admitted' 'to' '' '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54yr man with hx metastatic renal cell ca, c/o...</td>\n",
       "      <td>['54yr', 'man', 'with', 'hx', 'metastatic', 'r...</td>\n",
       "      <td>317</td>\n",
       "      <td>['54yr', 'man', 'with', 'hx', 'metastatic', 'r...</td>\n",
       "      <td>'54yr' 'man' 'with' 'hx' 'metastatic' 'renal' ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chief Complaint:\\n   24 Hour Events:\\n   - Per...</td>\n",
       "      <td>['Chief', 'Complaint', ':', '24', 'Hour', 'Eve...</td>\n",
       "      <td>1135</td>\n",
       "      <td>['chief', 'complaint', ':', '24', 'hour', 'eve...</td>\n",
       "      <td>'chief' 'complaint' '' '24' 'hour' 'events' ''...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chief Complaint:  Acute Hepatitis\\n   HPI:\\n  ...</td>\n",
       "      <td>['Chief', 'Complaint', ':', 'Acute', 'Hepatiti...</td>\n",
       "      <td>1976</td>\n",
       "      <td>['chief', 'complaint', ':', 'acute', 'hepatiti...</td>\n",
       "      <td>'chief' 'complaint' '' 'acute' 'hepatitis' 'hp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chief Complaint:\\n   HPI:\\n   24 Hour Events:\\...</td>\n",
       "      <td>['Chief', 'Complaint', ':', 'HPI', ':', '24', ...</td>\n",
       "      <td>567</td>\n",
       "      <td>['chief', 'complaint', ':', 'hpi', ':', '24', ...</td>\n",
       "      <td>'chief' 'complaint' '' 'hpi' '' '24' 'hour' 'e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  76 y/o M initially admitted to [**Hospital3 33...   \n",
       "1  54yr man with hx metastatic renal cell ca, c/o...   \n",
       "2  Chief Complaint:\\n   24 Hour Events:\\n   - Per...   \n",
       "3  Chief Complaint:  Acute Hepatitis\\n   HPI:\\n  ...   \n",
       "4  Chief Complaint:\\n   HPI:\\n   24 Hour Events:\\...   \n",
       "\n",
       "                                     tokenized_sents  sents_length  \\\n",
       "0  ['76', 'y/o', 'M', 'initially', 'admitted', 't...           901   \n",
       "1  ['54yr', 'man', 'with', 'hx', 'metastatic', 'r...           317   \n",
       "2  ['Chief', 'Complaint', ':', '24', 'Hour', 'Eve...          1135   \n",
       "3  ['Chief', 'Complaint', ':', 'Acute', 'Hepatiti...          1976   \n",
       "4  ['Chief', 'Complaint', ':', 'HPI', ':', '24', ...           567   \n",
       "\n",
       "                                        lower_tokens  \\\n",
       "0  ['76', 'y/o', 'm', 'initially', 'admitted', 't...   \n",
       "1  ['54yr', 'man', 'with', 'hx', 'metastatic', 'r...   \n",
       "2  ['chief', 'complaint', ':', '24', 'hour', 'eve...   \n",
       "3  ['chief', 'complaint', ':', 'acute', 'hepatiti...   \n",
       "4  ['chief', 'complaint', ':', 'hpi', ':', '24', ...   \n",
       "\n",
       "                                lower_no_punc_tokens  \n",
       "0  '76' 'yo' 'm' 'initially' 'admitted' 'to' '' '...  \n",
       "1  '54yr' 'man' 'with' 'hx' 'metastatic' 'renal' ...  \n",
       "2  'chief' 'complaint' '' '24' 'hour' 'events' ''...  \n",
       "3  'chief' 'complaint' '' 'acute' 'hepatitis' 'hp...  \n",
       "4  'chief' 'complaint' '' 'hpi' '' '24' 'hour' 'e...  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# skip\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'chief' 'complaint' '' '24' 'hour' 'events' '' '' 'pericardiocenesis' 'performed' '' '250' 'cc' 'of' 'serosanguinous' 'fluid' 'removed' '' 'sheath' 'pulled' '' 'totprot' '' '52' '' 'glucose' '' '57' '' 'ld' '' 'ldh' '' '' '1303' '' 'amylase' '' '48' '' 'albumin' '' '31' '' 'wbc' '' '2556' '' 'hct' '' 'fl' '' '4' '' 'meets' 'exudate' 'criteria' 'by' 'glucose' 'less' 'than' '60' 'and' 'protein' 'greater' 'than' '3' '' '' 'heparin' 'dcd' 'given' 'concern' 'it' 'might' 'worsen' 'hemorrhagic' 'effusion' '' 'rf' '27' '' 'up' 'from' '' '' '' '2153223' '' '' '' '' '' 'tsh' '21' '' 'rf' '27' '' 'c3' 'and' 'c4' 'pending' '' 'post' 'cath' 'check' '8' 'pm' 'unremarkable' '' 'tte' 'post' 'procedure' 'showed' 'tiny' 'residual' 'effusion' '' 'but' 'markedly' 'improved' '' '' 'started' 'indocin' '' 'contact' '' '' '' 'name' '' 'ni' '' '' '' '' 'rheumatology' 're' '' 'further' 'management' '' '11am' 'grewout' 'gpc' 's' 'from' 'pericardial' 'fluid' '' 'allergies' '' 'no' 'known' 'drug' 'allergies' 'last' 'dose' 'of' 'antibiotics' '' 'infusions' '' 'other' 'icu' 'medications' '' 'morphine' 'sulfate' '' '' '' '' '2157428' '' '' '' '1030' 'pm' 'other' 'medications' '' 'changes' 'to' 'medical' 'and' 'family' 'history' '' 'review' 'of' 'systems' 'is' 'unchanged' 'from' 'admission' 'except' 'as' 'noted' 'below' 'review' 'of' 'systems' '' 'chest' 'pain' 'improved' 'overall' '' 'although' 'still' 'present' 'with' 'deep' 'respiration' 'or' 'movement' '' 'flowsheet' 'data' 'as' 'of' '' '' '' '2157429' '' '' '' '0711' 'am' 'vital' 'signs' 'hemodynamic' 'monitoring' 'fluid' 'balance' '24' 'hours' 'since' '12' 'am' 'tmax' '' '374' 'c' '' '994' 'tcurrent' '' '364' 'c' '' '976' 'hr' '' '85' '' '85' '' '107' '' 'bpm' 'bp' '' '8254' '' '60' '' '' '8050' '' '36' '' '' '11572' '' '80' '' '' 'mmhg' 'rr' '' '16' '' '13' '' '26' '' 'inspmin' 'spo2' '' '95' '' 'heart' 'rhythm' '' 'sr' '' 'sinus' 'rhythm' '' 'wgt' '' 'current' '' '' '55' 'kg' '' 'admission' '' '' '55' 'kg' 'height' '' '64' 'inch' 'total' 'in' '' '1998' 'ml' 'po' '' '420' 'ml' 'tf' '' 'ivf' '' '1578' 'ml' 'blood' 'products' '' 'total' 'out' '' '2020' 'ml' '0' 'ml' 'urine' '' '1860' 'ml' 'ng' '' 'stool' '' 'drains' '' '160' 'ml' 'balance' '' '23' 'ml' '0' 'ml' 'respiratory' 'support' 'o2' 'delivery' 'device' '' 'none' 'spo2' '' '95' '' 'abg' '' '' 'physical' 'examination' 'general' '' 'resting' 'comfortably' 'in' 'bed' '' 'no' 'acute' 'distress' 'heent' '' 'sclera' 'anicteric' '' 'mmm' '' 'oropharynx' 'clear' 'neck' '' 'jvd' 'to' 'angle' 'of' 'mandible' 'at' '30' 'degrees' '' 'positive' 'hepatojugular' 'reflex' '' 'increased' 'jvp' 'with' 'deep' 'respiration' 'pulm' '' 'cta' 'bilaterally' '' 'no' 'wheezes' '' 'rales' '' 'or' 'rhonchi' 'cv' '' 'decreased' 'breath' 'sounds' '' 'tachycardic' '' 'normal' 's1s2' '' 'no' 'murmurs' '' 'no' 'appreciable' 'pericardial' 'rub' '' '' 'rub' 'with' 'inspiratory' 'variation' '' 'pulsus' '10' 'abdomen' '' 'normoactive' 'bowel' 'sounds' '' 'soft' '' 'nontender' '' 'nondistended' 'ext' '' 'warm' '' 'well' 'perfused' '' 'radial' 'and' 'dp' 'pulses' '2' '' 'no' 'edema' 'labs' '' 'radiology' '358' 'kul' '100' 'gdl' '95' 'mgdl' '07' 'mgdl' '23' 'meql' '39' 'meql' '14' 'mgdl' '105' 'meql' '139' 'meql' '295' '' '81' 'kul' '' 'image002jpg' '' 'labs' 'from' '' '' '' '2157427' '' '' '' '' 'labs' 'from' '' '' '' '2157428' '' '' '' 'reviewed' '' 'wbc' 'count' '' 'hematocrit' '' 'and' 'creatinine' 'stable' '' 'paracentesis' 'fluid' '' 'wbc' '' '2556' 'hct' '' 'fl' '' '4' 'polys' '' '34' 'lymphs' '' '39' 'monos' '' '12' 'eos' '' '3' 'macro' '' '12' 'totprot' '' '52' 'glucose' '' '57' 'ld' '' 'ldh' '' '' '1303' 'amylase' '' '48' 'albumin' '' '31' '' '' '' '2157428' '' '' '' '0507' 'am' '' '' '' '2157428' '' '' '' '0146' 'pm' 'wbc' '81' 'hct' '293' '295' 'plt' '358' 'cr' '07' 'tropt' '' '001' 'glucose' '95' 'other' 'labs' '' 'pt' '' 'ptt' '' 'inr13626812' '' 'ck' '' 'ckmb' '' 'troponint53' '' '001' '' 'differentialneuts732' '' '' 'lymph174' '' '' 'mono55' '' '' 'eos36' '' '' 'albumin38' 'gdl' '' 'ldh223' 'iul' '' 'ca92' 'mgdl' '' 'mg18' 'mgdl' '' 'po434' 'mgdl' 'tte' '' '' '' '' '2157428' '' '' '' '' '' 'overall' 'left' 'ventricular' 'systolic' 'function' 'is' 'normal' '' 'lvef' '' '55' '' '' '' 'right' 'ventricular' 'chamber' 'size' 'and' 'free' 'wall' 'motion' 'are' 'normal' '' 'the' 'mitral' 'valve' 'leaflets' 'are' 'mildly' 'thickened' '' 'there' 'is' 'a' 'trivialphysiologic' 'pericardial' 'effusion' '' 'a' 'catheter' 'is' 'seen' 'in' 'the' 'pericardial' 'space' '' 'there' 'are' 'no' 'echocardiographic' 'signs' 'of' 'tamponade' '' 'impression' '' 'tiny' 'residual' 'effusion' 'post' 'tap' '' 'no' 'evidence' 'of' 'tamponade' 'physiology' '' 'assessment' 'and' 'plan' '53f' 'with' 'ra' 'on' 'dmards' '' 'history' 'of' 'positive' 'ppd' 'sp' 'inh' 'treatment' 'admitted' 'with' 'pericardial' 'effusion' 'without' 'tamponade' 'physiology' '' 'now' 'growing' 'out' 'gpc' 'on' 'pericardial' 'fluid' 'culture' '' '' '' 'pericardial' 'effusion' '' 'fluid' 'consistent' 'with' 'exudate' '' 'also' 'sanguinous' '' 'given' 'exudative' 'and' 'with' 'low' 'glucose' '' 'secondary' 'to' 'ra' '' 'treatment' 'for' 'this' 'is' 'steroid' 'therapy' '' 'although' 'patient' 'with' 'postive' 'pericardial' 'fluid' 'culture' 'given' 'that' 'she' 'is' 'afebrile' '' 'without' 'leukocytosis' 'or' 'left' 'shift' '' 'and' 'overall' 'feeling' 'well' '' 'this' 'is' 'likely' 'a' 'contaminant' '' 'drainage' 'as' 'tapered' 'off' '' '' '50cc' 'since' 'placement' 'approximately' '20' 'hours' 'ago' '' 'still' 'with' 'distended' 'neck' 'veins' '' 'low' 'bp' '' 'likely' 'her' 'baseline' '' '' '' 'rheumatology' 'consult' '' 'consider' 'steroid' 'therapy' '' 'await' 'speciation' 'of' 'gpc' '' 'if' 'coag' 'positive' '' 'will' 'need' 'treatment' '' 'close' 'monitor' 'of' 'hemodynamics' '' 'pull' 'drain' 'this' 'afternoon' '' '' 'anemia' '' 'hematocrit' 'stable' '' 'within' 'past' '6' 'months' '' 'ranging' 'between' '3639' '' 'no' 'evidence' 'of' 'bleeding' 'or' 'reason' 'for' 'hemolysis' '' 'unclear' 'if' 'hemodilutional' '' 'although' 'unlikely' 'given' 'that' 'isolated' 'cell' 'line' 'down' '' 'even' 'if' 'above' 'effusion' 'is' 'hemorrhagic' '' 'would' 'not' 'expect' 'such' 'a' 'significant' 'hematocrit' 'drop' '' 'pericardium' 'likely' 'can' 'not' 'hold' 'this' 'quantity' 'of' 'blood' '' '' '' 'continue' 'folic' 'acid' 'per' 'home' 'regimen' '' 'retics' '' 'ldh' '' 'hapto' '' 'iron' 'studies' '' 'gc' 'stool' 'times' 'three' '' '' 'fever' '' 'resolved' '' '' '' 'acute' 'kidney' 'injury' '' 'resolved' '' 'likely' 'prerenal' '' '' '' 'rheumatoid' 'arthritis' '' 'patient' 'denies' 'flares' 'of' 'disease' '' 'disease' 'has' 'been' 'stable' 'since' 'diagnosis' 'in' '' '' '' '2149' '' '' '' '' 'rf' 'now' 'positive' '' '' 'continue' 'plaquenil' 'per' 'home' 'regimen' '' 'discuss' 'with' 'rheumatology' 'if' 'okay' 'to' 'restart' 'methotrexate' '' 'rheum' 'consult' '' 'as' 'above' '' '' 'osteoporosis' '' '' 'continue' 'calcium' '' 'vitamin' 'd' 'per' 'home' 'regimen' '' '' 'chronic' 'pain' '' '' 'continue' 'gabapentin' '' 'amitryptiline' 'per' 'home' 'regimen' 'prophylaxis' '' 'pneumoboots' '' 'ambulation' 'bowel' 'regimen' 'prn' 'no' 'indication' 'for' 'ppi' 'at' 'this' 'time' 'full' 'code' 'icu' 'care' 'nutrition' '' 'glycemic' 'control' '' 'lines' '' '20' 'gauge' '' '' '' '' '2157427' '' '' '' '1124' 'pm' 'prophylaxis' '' 'dvt' '' 'stress' 'ulcer' '' 'vap' '' 'comments' '' 'communication' '' 'comments' '' 'code' 'status' '' 'full' 'code' 'disposition' ''\""
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# skip\n",
    "df_clean['lower_no_punc_tokens'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Coronary artery bypass graft (CABG)\\n   Assess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subdural hemorrhage (SDH)\\n   Assessment:\\n   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coronary artery bypass graft (CABG)\\n   Assess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Coronary artery bypass graft (CABG)\\n   Assess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Demographics\\n   Day of intubation:\\n   Day of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Coronary artery bypass graft (CABG)\\n   Assess...\n",
       "1  Subdural hemorrhage (SDH)\\n   Assessment:\\n   ...\n",
       "2  Coronary artery bypass graft (CABG)\\n   Assess...\n",
       "3  Coronary artery bypass graft (CABG)\\n   Assess...\n",
       "4  Demographics\\n   Day of intubation:\\n   Day of..."
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Demographics\\n   Day of intubation:\\n   Day of mechanical ventilation: 6\\n   Ideal body weight: 72.6 None\\n   Ideal tidal volume: 290.4 / 435.6 / 580.8 mL/kg\\n   Airway\\n   Airway Placement Data\\n   Known difficult intubation: No\\n   Procedure location:\\n   Reason:\\n   Tube Type\\n   ETT:\\n                   Position:  cm at teeth\\n                   Route:\\n                   Type: Standard\\n                   Size: 8mm\\n   Tracheostomy tube:\\n                   Type:\\n                   Manufacturer:\\n                   Size:\\n                   PMV:\\n   Cuff  Management:\\n                   Vol/Press:\\n                                   Cuff pressure:   cmH2O\\n                                   Cuff volume:   mL /\\n                   Airway problems:\\n                   Comments:\\n   Lung sounds\\n   RLL Lung Sounds: Diminished\\n   RUL Lung Sounds: Clear\\n   LUL Lung Sounds: Clear\\n   LLL Lung Sounds: Diminished\\n   Comments:\\n   Secretions\\n   Sputum color / consistency: Tan / Thick\\n   Sputum source/amount: Suctioned / Moderate\\n   Comments:\\n   Ventilation Assessment\\n   Level of breathing assistance:\\n   Visual assessment of breathing pattern: Normal quiet breathing\\n   Assessment of breathing comfort:\\n   Non-invasive ventilation assessment:\\n   Invasive ventilation assessment:\\n   Trigger work assessment: Triggering synchronously\\n   Dysynchrony assessment:\\n   Comments:\\n   Plan\\n   Next 24-48 hours: Continue with daily RSBI tests & SBT's as tolerated\\n   Reason for continuing current ventilatory support: Underlying illness\\n   not resolved\\n   Respiratory Care Shift Procedures\\n   Transports:\\n   Destination (R/T)\\n   Time\\n   Complications\\n   Comments\\n   Bedside Procedures:\\n   Comments:\\n   Respiratory Care:\\n   Pt tolerated PSV all shift, no parameter changes made. Received MDI\\n   morning RSBI = 51. Placed on SBT at 0630.\\n\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_spacy(df, text_col=None, tokenization_type='clean', outfile=None):\n",
    "    tok_snts = []\n",
    "    if outfile is not None: f = open(outfile, 'w', encoding='utf8')\n",
    "    data = df if text_col is None else df[text_col]\n",
    "    for snt in data:\n",
    "        tkns = nlp.tokenizer(snt)\n",
    "        if ('low' in tokenization_type) and ('wos' in tokenization_type):\n",
    "            _tkns = [str(x.text).lower() for x in tkns if not x.is_space]\n",
    "        elif 'wos' in tokenization_type:\n",
    "            _tkns = [str(x.text) for x in tkns if not x.is_space]\n",
    "        elif 'lem' in tokenization_type:\n",
    "            _tkns = [str(x.lemma_).lower() for x in tkns if not x.is_space and not x.is_punct]\n",
    "        elif 'stem' in tokenization_type:\n",
    "            _tkns = [stemmer.stem(str(x.text).lower()) for x in tkns if not x.is_space and not x.is_punct]\n",
    "        else: # clean by default\n",
    "            _tkns = [str(x.text).lower() for x in tkns if not x.is_space and not x.is_punct]\n",
    "        \n",
    "        if outfile is not None: # flush to file if option selected\n",
    "            f.write(\"{}\\n\".format(\"\\t\".join(_tkns)))\n",
    "        else: # otherwise save in variable\n",
    "            tok_snts.append(_tkns)\n",
    "\n",
    "    return tok_snts if outfile is None else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_spacy(df, text_col='text', tokenization_type='clean', outfile = './notes_clean.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now to step 3 - run gensim model \n",
    "# use notes_clean.txt\n",
    "\n",
    "#ignote- use df_clean i.e. the .gz file - maybe just lower_no_punc_tokens column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sumithra file: for reference :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import tarfile\n",
    "import pandas as pd\n",
    "import os\n",
    "from collections import Counter\n",
    "import spacy\n",
    "import re\n",
    "import gzip\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy.load('en')\n",
    "\n",
    "from spacy.lang.en import English\n",
    "#nlp = English(parser=False, entity=False)\n",
    "nlp = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "filecount = 0\n",
    "no_of_text_fields = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar = tarfile.open('/Users/sumithra/DSV/MeDESTO/mimic_experiments/mimic_only_notes.tar.gz', 'r:gz')\n",
    "no_of_files = len(tar.getmembers())\n",
    "tar_members = tar.getmembers()\n",
    "f_out = gzip.open('/Users/sumithra/DSV/MeDESTO/mimic_experiments/mimic_tokenized_non_alpha.txt.gz', 'wb:gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## loop over all tar members\n",
    "for tar_info in tar_members:\n",
    "    filecount += 1\n",
    "    t = tar_info.name\n",
    "\n",
    "    print t+\" (\"+str(filecount)+\" of \"+str(len(tar_members))+\")\"\n",
    "#    if filecount == 2:\n",
    "#        break\n",
    "\n",
    "    ## extract the file\n",
    "    f = tar.extractfile(t)\n",
    "    ## some files are empty - skip these\n",
    "    if(f.size<=0):\n",
    "        print \"\\t\\t\\t\\t\\tskipping: \"+t\n",
    "        continue\n",
    "    chunksize = 1000000\n",
    "    # read the csv - using only text and category columns (the category column could potentially be interesting to study further later?)\n",
    "    notefile = pd.read_csv(f, header=0, usecols=['TEXT', 'CATEGORY'],chunksize=chunksize, error_bad_lines=False)\n",
    "\n",
    "    for note_text in notefile:\n",
    "        ## collapse all multiple newlines to one from all 'TEXT' columns in the file - only if the content in the column is a string\n",
    "        note_text = [re.sub(\"\\n+\",\"\\n\", test.decode('UTF-8')) for test in note_text['TEXT'] if type(test)==str]\n",
    "        ## replace all anonymization values with \"ANON\" for better tokenization\n",
    "        note_text = [re.sub(\"\\[\\*\\*.*?\\*\\*\\]\",\"ANON\", test) for test in note_text]\n",
    "        ## some notes have long sequences of underscores, remove these\n",
    "        note_text = [re.sub(\"\\_+\",\"\", test) for test in note_text]\n",
    "        ## apply spacy English model on all texts to extract sentences and words\n",
    "        docs = [nlp(unicode(t)) for t in note_text]\n",
    "        ## for now, remove all non-alpha numeric characters, and convert everything to lower case\n",
    "        ## s.orth__ is spacy's token representation for the original word - this can be changed to e.g. s.lemma_\n",
    "        all_sentences = [[re.sub(\"\\W\", \" \", s.orth_.lower()) for s in doc.sents] for doc in docs]\n",
    "        ## collapse all sequences of whitespace to only space\n",
    "        all_sentences = [[re.sub(\"\\s+\", \" \", words) for words in sentence] for sentence in all_sentences]\n",
    "        for sentences in all_sentences:\n",
    "            #print t\n",
    "            f_out.writelines('\\n'.join(sentences))\n",
    "\n",
    "        \n",
    "f_out.close()\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
